{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape = (40,40,3))\n",
    "\n",
    "\n",
    "x = layers.Conv2D(32,3,activation='relu')(input)\n",
    "x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(1024,activation='relu')(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(7,activation='softmax')(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer = 'adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dir = r'C:\\Users\\Bhavani\\emotion\\dataset\\train'\n",
    "\n",
    "traindata = train.flow_from_directory(train_dir,batch_size=10, target_size=(40,40),class_mode='categorical')\n",
    "\n",
    "test_dir =  r'C:\\Users\\Bhavani\\emotion\\dataset\\test'\n",
    "testdata = train.flow_from_directory(test_dir,batch_size=10, target_size=(40,40),class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2871 steps, validate for 718 steps\n",
      "Epoch 1/30\n",
      "2871/2871 [==============================] - 570s 198ms/step - loss: 1.6034 - acc: 0.3687 - val_loss: 1.4232 - val_acc: 0.4451\n",
      "Epoch 2/30\n",
      "2871/2871 [==============================] - 340s 118ms/step - loss: 1.4250 - acc: 0.4526 - val_loss: 1.3798 - val_acc: 0.4645\n",
      "Epoch 3/30\n",
      "2871/2871 [==============================] - 381s 133ms/step - loss: 1.3314 - acc: 0.4923 - val_loss: 1.3014 - val_acc: 0.5028\n",
      "Epoch 4/30\n",
      "2871/2871 [==============================] - 392s 136ms/step - loss: 1.2549 - acc: 0.5274 - val_loss: 1.2479 - val_acc: 0.5195\n",
      "Epoch 5/30\n",
      "2871/2871 [==============================] - 394s 137ms/step - loss: 1.1708 - acc: 0.5568 - val_loss: 1.2379 - val_acc: 0.5279\n",
      "Epoch 6/30\n",
      "2871/2871 [==============================] - 373s 130ms/step - loss: 1.0913 - acc: 0.5915 - val_loss: 1.2376 - val_acc: 0.5313\n",
      "Epoch 7/30\n",
      "2871/2871 [==============================] - 382s 133ms/step - loss: 1.0170 - acc: 0.6214 - val_loss: 1.2292 - val_acc: 0.5357\n",
      "Epoch 8/30\n",
      "2871/2871 [==============================] - 384s 134ms/step - loss: 0.9351 - acc: 0.6523 - val_loss: 1.2360 - val_acc: 0.5458\n",
      "Epoch 9/30\n",
      "2871/2871 [==============================] - 381s 133ms/step - loss: 0.8686 - acc: 0.6811 - val_loss: 1.2383 - val_acc: 0.5508\n",
      "Epoch 10/30\n",
      "2871/2871 [==============================] - 385s 134ms/step - loss: 0.8090 - acc: 0.7052 - val_loss: 1.2455 - val_acc: 0.5422\n",
      "Epoch 11/30\n",
      "2871/2871 [==============================] - 399s 139ms/step - loss: 0.7503 - acc: 0.7260 - val_loss: 1.2409 - val_acc: 0.5546\n",
      "Epoch 12/30\n",
      "2871/2871 [==============================] - 398s 139ms/step - loss: 0.7033 - acc: 0.7444 - val_loss: 1.3132 - val_acc: 0.5527\n",
      "Epoch 13/30\n",
      "2871/2871 [==============================] - 418s 146ms/step - loss: 0.6562 - acc: 0.7620 - val_loss: 1.3024 - val_acc: 0.5548\n",
      "Epoch 14/30\n",
      "2871/2871 [==============================] - 698s 243ms/step - loss: 0.6240 - acc: 0.7735 - val_loss: 1.3260 - val_acc: 0.5543\n",
      "Epoch 15/30\n",
      "2871/2871 [==============================] - 787s 274ms/step - loss: 0.5923 - acc: 0.7870 - val_loss: 1.3703 - val_acc: 0.5548\n",
      "Epoch 16/30\n",
      "2871/2871 [==============================] - 615s 214ms/step - loss: 0.5676 - acc: 0.7966 - val_loss: 1.3536 - val_acc: 0.5521\n",
      "Epoch 17/30\n",
      "2871/2871 [==============================] - 352s 123ms/step - loss: 0.5376 - acc: 0.8092 - val_loss: 1.3834 - val_acc: 0.5515\n",
      "Epoch 18/30\n",
      "2871/2871 [==============================] - 305s 106ms/step - loss: 0.5049 - acc: 0.8205 - val_loss: 1.4778 - val_acc: 0.5536\n",
      "Epoch 20/30\n",
      "2871/2871 [==============================] - 308s 107ms/step - loss: 0.4753 - acc: 0.8349 - val_loss: 1.4543 - val_acc: 0.5588\n",
      "Epoch 22/30\n",
      "2871/2871 [==============================] - 334s 116ms/step - loss: 0.4502 - acc: 0.8440 - val_loss: 1.4836 - val_acc: 0.5543\n",
      "Epoch 23/30\n",
      "2871/2871 [==============================] - 332s 115ms/step - loss: 0.4391 - acc: 0.8447 - val_loss: 1.5326 - val_acc: 0.5575\n",
      "Epoch 24/30\n",
      "2871/2871 [==============================] - 332s 116ms/step - loss: 0.4336 - acc: 0.8510 - val_loss: 1.4620 - val_acc: 0.5440\n",
      "Epoch 25/30\n",
      "2871/2871 [==============================] - 343s 120ms/step - loss: 0.4316 - acc: 0.8527 - val_loss: 1.5612 - val_acc: 0.5532\n",
      "Epoch 26/30\n",
      "2871/2871 [==============================] - 337s 117ms/step - loss: 0.4212 - acc: 0.8552 - val_loss: 1.5863 - val_acc: 0.5589\n",
      "Epoch 27/30\n",
      "2871/2871 [==============================] - 336s 117ms/step - loss: 0.4041 - acc: 0.8611 - val_loss: 1.5613 - val_acc: 0.5627\n",
      "Epoch 28/30\n",
      "2871/2871 [==============================] - 343s 119ms/step - loss: 0.4075 - acc: 0.8616 - val_loss: 1.4816 - val_acc: 0.5589\n",
      "Epoch 29/30\n",
      "2871/2871 [==============================] - 342s 119ms/step - loss: 0.3898 - acc: 0.8666 - val_loss: 1.5307 - val_acc: 0.5577\n",
      "Epoch 30/30\n",
      "2871/2871 [==============================] - 341s 119ms/step - loss: 0.3808 - acc: 0.8701 - val_loss: 1.5947 - val_acc: 0.5539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a671d4748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(traindata,epochs=30,verbose=1,validation_data = testdata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: emotion\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\angry\\Training_345125.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\disgust\\Training_13740441.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\fear\\Training_893818.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\happy\\Training_625682.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\neutral\\Training_980544.jpg', target_size =(40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\sad\\Training_2350940.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_pred = image.load_img(r'C:\\Users\\Bhavani\\emotion\\dataset\\train\\surprise\\Training_1359028.jpg', target_size = (40,40))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "rslt = model.predict(img_pred)\n",
    "label=np.argmax(rslt,axis=1)[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
